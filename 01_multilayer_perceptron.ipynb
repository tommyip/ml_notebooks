{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d29b1b-5ef8-4356-af94-ec576a6becb5",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3a70fd8b-f654-47d1-b313-1c736aa9d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c35c9-56f4-475a-a975-bc73789e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "y = np.array([0., 1., 1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "dc3a8692-274c-426f-bdef-ef77e34ed899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORNetwork:\n",
    "    def __init__(self):\n",
    "        # Parameters\n",
    "        self.W = np.random.randn(2, 4)\n",
    "        self.c = np.random.randn(4)\n",
    "        self.w = np.random.randn(4)\n",
    "        self.b = np.random.randn(1)\n",
    "\n",
    "    def __call__(self, x: np.ndarray):\n",
    "        self.x = x\n",
    "        self.h = self.W.T @ x + self.c\n",
    "        self.a = np.maximum(self.h, 0)\n",
    "        return np.dot(self.w, self.a) + self.b\n",
    "\n",
    "    def backwards(self, loss_grad: float):\n",
    "        self.w_grad = loss_grad * self.a\n",
    "        self.b_grad = loss_grad\n",
    "        loss_grad = self.w * loss_grad  # Backprop through linear output\n",
    "        loss_grad = loss_grad * (self.h >= 0) # Backprop through ReLU\n",
    "        self.W_grad = np.outer(self.x, loss_grad.T)\n",
    "        self.c_grad = loss_grad\n",
    "\n",
    "    def optim_step(self, lr=0.001):\n",
    "        self.W -= self.W_grad * lr\n",
    "        self.c -= self.c_grad * lr\n",
    "        self.w -= self.w_grad * lr\n",
    "        self.b -= self.b_grad * lr\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    return np.pow(y - y_hat, 2)\n",
    "\n",
    "def mse_grad(y, y_hat):\n",
    "    return -2 * (y - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0ab54438-eafc-471f-83b6-09920d7355ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[0. 0.] y=0.0 y_hat=1.38240\n",
      "x=[0. 1.] y=1.0 y_hat=3.08159\n",
      "x=[1. 0.] y=1.0 y_hat=0.25986\n",
      "x=[1. 1.] y=0.0 y_hat=1.95905\n",
      "loss = 10.62976\n"
     ]
    }
   ],
   "source": [
    "# See prediction using random weights\n",
    "np.random.seed(1)\n",
    "xor_model = XORNetwork()\n",
    "y_hat = np.array([xor_model(xi).item() for xi in X])\n",
    "for xi, yi, yi_hat in zip(X, y, y_hat):\n",
    "    print(f'x={xi} y={yi} y_hat={yi_hat:.5f}')\n",
    "print(f'loss = {np.mean(np.sum(mse(y, y_hat))):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "eada0d7a-5029-485b-b007-6f6380af1eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss = 2.30893782\n",
      "Epoch 100 | loss = 0.15412496\n",
      "Epoch 200 | loss = 0.02602696\n",
      "Epoch 300 | loss = 0.00119032\n",
      "Epoch 400 | loss = 0.00009959\n",
      "Epoch 500 | loss = 0.00001583\n",
      "Epoch 600 | loss = 0.00000411\n",
      "Epoch 700 | loss = 0.00000153\n",
      "Converged at epoch 755 | loss = 0.00000099\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xor_model = XORNetwork()\n",
    "\n",
    "# Training the XOR network\n",
    "epilson = 0.000001\n",
    "lr = 0.05\n",
    "max_epochs = 10000\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    loss = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        yi_hat = xor_model(xi)\n",
    "        loss += 0.25 * mse(yi, yi_hat)\n",
    "        loss_grad = mse_grad(yi, yi_hat)\n",
    "        xor_model.backwards(loss_grad)\n",
    "        xor_model.optim_step(lr)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} | loss = {loss.item():.8f}')\n",
    "    if loss <= epilson:\n",
    "        print(f'Converged at epoch {epoch} | loss = {loss.item():.8f}')\n",
    "        break\n",
    "    lr *= 0.997\n",
    "else:\n",
    "    print(f'Failed to converge | loss = {loss.item():.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "91f260b9-a77c-43dd-a8d3-644a56604e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[0. 0.] y=0.0 y_hat=0.00156\n",
      "x=[0. 1.] y=1.0 y_hat=0.99927\n",
      "x=[1. 0.] y=1.0 y_hat=0.99916\n",
      "x=[1. 1.] y=0.0 y_hat=0.00036\n",
      "loss = 0.00000\n"
     ]
    }
   ],
   "source": [
    "# Check predictions\n",
    "y_hat = np.array([xor_model(xi).item() for xi in X])\n",
    "for xi, yi, yi_hat in zip(X, y, y_hat):\n",
    "    print(f'x={xi} y={yi} y_hat={yi_hat:.5f}')\n",
    "print(f'loss = {np.mean(np.sum(mse(y, y_hat))):.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
